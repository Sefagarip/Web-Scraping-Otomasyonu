# Web Scraping Automation - Web Scraping Otomasyonu

ğŸ“ŒğŸ“Œ Read this in: [English](#web-scraping-automation) | [TÃ¼rkÃ§e](#web-scraping-otomasyonu)

## Web Scraping Automation
This project is a comprehensive Selenium-based automation tool developed for web scraping and performing automated operations on websites. With its user-friendly interface, it allows even those without technical knowledge to easily perform web scraping and automation tasks.

### Features

- **Easy to Use**: Menu-based interface for simple automation operations
- **Web Browsing**: Navigate through websites, interact with elements and extract data
- **Data Collection**: Reading text, exporting table data to CSV/Excel
- **Image Download**: Automatically download images from websites
- **Combination Feature**: Perform multiple operations in sequence automatically
- **Parameter Memory**: Ability to reuse previous parameters for repeating the same operations

### Installation

1. Download and install Python from [python.org](https://www.python.org/downloads/)
2. Download or clone the project:
   ```
   git clone https://github.com/Sefagarip/Web-Scraping-Otomasyonu.git
   cd Web-Scraping-Otomasyonu
   ```
3. Install the required dependencies:
   ```
   pip install -r requirements.txt
   ```

### Usage

To run the program:

```
python "web scraping otomasyonu.py"
```

#### Main Menu Options

1. **Start browser**: Opens Chrome browser
2. **Go to URL**: Navigates to the specified web address
3. **Click on element**: Clicks on the selected HTML element
4. **Write text**: Writes text to the specified element
5. **Send Enter key**: Sends the Enter key
6. **Send special key**: Sends special keys like ENTER, TAB, ESC
7. **Read text**: Reads the text of the specified element
8. **Read multiple texts**: Reads text from multiple elements
9. **Add waiting time**: Waits for the specified duration
10. **Read table**: Finds an HTML table and converts it to a pandas DataFrame
11. **Read data from all tables**: Collects data from all tables with pagination
12. **Scroll**: Scrolls up/down within the page or an element
13. **Open new tab**: Opens a new tab
14. **Switch tab**: Switches to the specified tab
15. **Close active tab**: Closes the current tab
16. **Download images**: Downloads selected image elements to the computer
17. **Close browser**: Closes the Chrome browser
18. **Run Combination**: Runs multiple steps automatically in sequence

#### Using Combinations

With the combination feature, you can perform multiple operations in sequence automatically:

1. Select "18. Run Combination" from the main menu
2. Enter the numbers of the operations you want to perform separated by spaces (e.g., "3 12 9 7")
3. The program will run each step in sequence and ask you for the necessary information
4. When you use the same step again, you can choose whether to use the previous information

#### Example Usage Scenario

To collect product information from a website:
1. Start the browser
2. Go to an e-commerce site
3. Click on the search box
4. Write "Phone" and search
5. Read the results as a table
6. Export the data to Excel

### Dependencies

- Python 3.6+
- Selenium
- pandas
- webdriver-manager
- requests

### Contact

For questions or suggestions, you can use the [GitHub Issues](https://github.com/Sefagarip/Web-Scraping-Otomasyonu/issues) section.


## Web Scraping Otomasyonu

Bu proje, web sitelerinden veri Ã§ekme ve otomatik iÅŸlemler gerÃ§ekleÅŸtirme amacÄ±yla geliÅŸtirilmiÅŸ Selenium tabanlÄ± kapsamlÄ± bir otomasyon aracÄ±dÄ±r. KullanÄ±cÄ± dostu arayÃ¼zÃ¼ ile teknik bilgisi olmayan kiÅŸilerin bile kolayca web scraping ve otomasyon iÅŸlemleri yapabilmesini saÄŸlar.

## Ã–zellikler

- **Kolay KullanÄ±m**: MenÃ¼ tabanlÄ± TÃ¼rkÃ§e arayÃ¼z ile kolayca otomasyon iÅŸlemleri yapabilme
- **Web Tarama**: Web sitelerinde gezinme, etkileÅŸim ve veri Ã§ekme
- **Veri Toplama**: Metin okuma, tablo verilerini CSV/Excel'e aktarma
- **Resim Ä°ndirme**: Web sitelerinden resimleri otomatik olarak indirme
- **Kombinasyon Ã–zelliÄŸi**: Birden fazla iÅŸlemi sÄ±rayla otomatik olarak gerÃ§ekleÅŸtirme
- **Parametreleri HatÄ±rlama**: AynÄ± iÅŸlemleri tekrar gerÃ§ekleÅŸtirmek iÃ§in Ã¶nceki parametreleri kullanabilme

## Kurulum

1. Python'u [python.org](https://www.python.org/downloads/) adresinden indirip kurun.
2. Projeyi indirin veya klonlayÄ±n:
   ```
   git clone https://github.com/Sefagarip/Web-Scraping-Otomasyonu.git
   cd Web-Scraping-Otomasyonu
   ```
3. Gerekli baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin:
   ```
   pip install -r requirements.txt
   ```

## KullanÄ±m

ProgramÄ± Ã§alÄ±ÅŸtÄ±rmak iÃ§in:

```
python "web scraping otomasyonu.py"
```

### Ana MenÃ¼ SeÃ§enekleri

1. **TarayÄ±cÄ± baÅŸlat**: Chrome tarayÄ±cÄ±sÄ±nÄ± aÃ§ar
2. **URL'ye git**: Belirtilen web adresine gider
3. **Elemente tÄ±kla**: SeÃ§ilen HTML elementine tÄ±klar
4. **Metin yaz**: Belirtilen elemente metin yazar
5. **Enter tuÅŸu gÃ¶nder**: Enter tuÅŸu gÃ¶nderir
6. **Ã–zel tuÅŸ gÃ¶nder**: ENTER, TAB, ESC gibi Ã¶zel tuÅŸlar gÃ¶nderir
7. **Metin oku**: Belirtilen elementin metnini okur
8. **Ã‡oklu metin oku**: Birden fazla elementin metnini okur
9. **Bekleme sÃ¼resi ekle**: Belirtilen sÃ¼re kadar bekler
10. **Tablo oku**: HTML tablosunu bulup pandas DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r
11. **TÃ¼m tablolarda veri oku**: Sayfalama yaparak tÃ¼m tablolardaki verileri toplar
12. **Scroll yap**: Sayfada veya element iÃ§inde aÅŸaÄŸÄ±/yukarÄ± kaydÄ±rma yapar
13. **Yeni sekme aÃ§**: Yeni bir sekme aÃ§ar
14. **Sekme deÄŸiÅŸtir**: Belirtilen sekmeye geÃ§iÅŸ yapar
15. **Aktif sekmeyi kapat**: Mevcut sekmeyi kapatÄ±r
16. **Resimleri indir**: SeÃ§ilen resim elementlerini bilgisayara indirir
17. **TarayÄ±cÄ±yÄ± kapat**: Chrome tarayÄ±cÄ±sÄ±nÄ± kapatÄ±r
18. **Kombinasyon Ã‡alÄ±ÅŸtÄ±r**: Birden fazla adÄ±mÄ± otomatik olarak sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±r

### Kombinasyon KullanÄ±mÄ±

Kombinasyon Ã¶zelliÄŸi sayesinde birÃ§ok iÅŸlemi sÄ±rayla otomatik olarak gerÃ§ekleÅŸtirebilirsiniz:

1. Ana menÃ¼den "18. Kombinasyon Ã‡alÄ±ÅŸtÄ±r" seÃ§eneÄŸini seÃ§in
2. Yapmak istediÄŸiniz iÅŸlemlerin numaralarÄ±nÄ± boÅŸlukla ayÄ±rarak girin (Ã¶rn: "3 12 9 7")
3. Program sÄ±rayla her adÄ±mÄ± Ã§alÄ±ÅŸtÄ±racak ve gerekli bilgileri sizden isteyecektir
4. AynÄ± adÄ±mÄ± tekrar kullandÄ±ÄŸÄ±nÄ±zda, Ã¶nceki bilgileri kullanÄ±p kullanmamayÄ± seÃ§ebilirsiniz

### Ã–rnek KullanÄ±m Senaryosu

Bir web sitesindeki Ã¼rÃ¼n bilgilerini toplamak iÃ§in:
1. TarayÄ±cÄ±yÄ± baÅŸlat
2. E-ticaret sitesine git
3. Arama kutusuna tÄ±kla 
4. "Telefon" yazÄ±p ara
5. SonuÃ§larÄ± tablo olarak oku
6. Verileri Excel'e aktar

## BaÄŸÄ±mlÄ±lÄ±klar

- Python 3.6+
- Selenium
- pandas
- webdriver-manager
- requests

## Ä°letiÅŸim

SorularÄ±nÄ±z veya Ã¶nerileriniz iÃ§in [GitHub Issues](https://github.com/Sefagarip/Web-Scraping-Otomasyonu/issues) bÃ¶lÃ¼mÃ¼nÃ¼ kullanabilirsiniz.
